{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt, seaborn as sn, numpy as np, pandas as pd\n",
    "sn.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Inference and Monte Carlo methods\n",
    "\n",
    "This notebook introduces a Bayesian approach to model calibration and also presents the basics of how to use Monte Carlo (MC) methods to sample from difficult distributions.\n",
    "\n",
    "## 1.1. A Bayesian model calibration framework\n",
    "\n",
    "At the end of the first notebook we introduced Bayes' Theorem:\n",
    "\n",
    "$$P(y \\mid x) = \\frac{P(x \\mid y)P(y)}{\\int_y P(x \\mid y)P(y) dy}$$\n",
    "\n",
    "and in the second notebook we discussed model auto-calibration, which led us to the concept of the likelihood function. \n",
    "\n",
    "In a typical calibration situtaion we have an environmental model that includes some poorly defined parameters, and we will also have observed data for the variable we're trying to simulate, together with contemporary observations for all the input datasets we need to run the model. We often also have some idea of roughly what values the parameters should take (e.g. from ranges in the literature), but we don't know enough about them to be able to use the model without calibrating it. \n",
    "\n",
    "There are lots of different ways of calibrating models, but here we're going to focus on the Bayesian approach. In this case, the aim of model calibration is to start off with whatever **prior information** we have about the parameters (e.g. literature values) and then **refine** these estimates using the observed data. If our model has $\\theta =  \\{\\theta_1, .., \\theta_n\\}$ poorly constrained parameters, we can capture our **prior** beliefs by defining distributions for each of them. For example, in the simplest case we might define **uniform distributions** for each parameter with the maximum and minimum values for each distribution based upon literature ranges. The **joint distribution** over all the $\\theta_i$ is the **prior distribution**, $P(\\theta)$, of our parameters.\n",
    "\n",
    "We want to take the prior distribution and *update* it based on the observed data. In other words, we want to calculate a new distribution for the parameters **given** the observations, $P(\\theta \\mid D)$, where $D$ is the observed data. This is called the **posterior distribution**, because it represents what we know about the parameters **after** we've incorporated the information from the observations. Once we have the posterior distribution, we can calculate **marginal posteriors** for each parameter, which we can compare to our prior distributions to see how much we've learned from the calibration process (see notebook 1 for a quick overview of marginalisation).\n",
    "\n",
    "So, we want to calculate $P(\\theta \\mid D)$, but it's not immediately obvious how to do this. This is where Bayes' Theorem comes in. From the equation above, we can write:\n",
    "\n",
    "$$P(\\theta \\mid D) = \\frac{P(D \\mid \\theta)P(\\theta)}{\\int_y P(D \\mid \\theta)P(\\theta) d\\theta}$$\n",
    "\n",
    "How does this help? Well, $P(\\theta)$ is the prior distribution, which we already know. $P(D \\mid \\theta)$ is the probability of the observations, *given* a particular set of parameters. In other words, if we run the model with a particular set of parameters, what is the probabiltiy that it produces the observed data? From notebook 2, you should be able to see that this is the **likelihood function**. Working out the likelihood function can be tricky but, as we've seen previously, if you make some assumptions you can usually write it down. This gives us everything we need to work out the right-hand side of the equation above: the numerator in the fraction is the prior multiplied by the likelihood, and the denominator is the integral of the numerator over the entire parameter space. This integral is actually just a constant: it's a scaling factor which \"normalises\" the numerator so that the total volume under the posterior surface is equal to one. It is properly referred to as **the probability of the data** or, sometimes, as the **evidence**, but it's also often just called the **normalising constant**.\n",
    "\n",
    "This means we can re-write Bayes' Theorem as:\n",
    "\n",
    "$$posterior = \\frac{likelihood \\times prior}{normalising\\;constant}$$\n",
    "\n",
    "In principle, at least, Bayes' Theorem gives us everything we need to calculate $P(\\theta \\mid D)$. In practice, the integral in the denominator tends to be very tricky to evaluate because it frequently has no analytical solution. Also, because it involves integrating over the *entire* parameter space, numerical approximations of the integral are often very *expensive* to calculate (i.e. they take a long time to run). Fortunately, in many application we don't need to know the exact posterior distribution - anything *proportional* to it will do. Because the denominator in Bayes' equation is ultimately just a constant, we often ignore it and write:\n",
    "\n",
    "$$P(\\theta \\mid D) \\propto P(D \\mid \\theta)P(\\theta)$$\n",
    "\n",
    "$$posterior \\propto likelihood \\times prior$$\n",
    "\n",
    "## 1.2. Conjugate priors\n",
    "\n",
    "The difficulty of evaluating the posterior depends on the complexity of the prior distribution and likelihood function. If the likelihood is something simple, like a Gaussian, we can often make life easier for ourselves by choosing a **[conjugate prior](https://en.wikipedia.org/wiki/Conjugate_prior)** to ensure that the posterior will also be a friendly function. \n",
    "\n",
    "Choosing your prior to make the calculations easier might seem a bit arbitrary, and in fact this is one area where the Bayesian approach often comes in for criticism. However it's worth emphasising that, regardless of whether you adopt a Bayesian or a Frequentist paradigm, **[\"you can't do inference without making assumptions\"](http://www.inference.phy.cam.ac.uk/itila/ \"Quote from page 51 of David MacKay's book\")**. Clearly you should only choose a conjugate prior if it also makes sense based on what you know about your parameters, but if you have a choice between two reasonable-looking alternatives, one of which is conjugate, you might as well makes things as straightforward as possible.\n",
    "\n",
    "Once we have the posterior distribution in a suitable form, we can calculate marginal distributions for each parameter by integrating. Recall from notebook 1 that for a two-dimensional joint distribution, $P(x,y)$, the marginal distribution for $x$ was obtained by \"integrating out\" $y$:\n",
    "\n",
    "$$P(x) = \\int_y P(x,y) dy$$\n",
    "\n",
    "If our model has $n$ parameters, $\\{\\theta_1, .., \\theta_n\\}$, then the marginal distribution for each parameter is found by \"integrating out\" all the others.\n",
    "\n",
    "## 1.3. Practical difficulties\n",
    "\n",
    "We're not going to delve into the details of conjugate priors any further because for the purposes of calibrating complex models we won't find them very useful. This is because in most cases the likelihood function will not be a simple distribution for which an obvious conjugate prior exists. More often than not, the likelihood function will be something pretty horrible that makes the posterior density impossible to integrate analytically.\n",
    "\n",
    "In general, when working with conceptual environmental models, we will often find ourselves in a situation where we can evaluate the posterior density for any point in the parameter space, but we can't write down an equation to represent it. If this sounds odd, consider the example of the \"black box\" model from notebook 2. This model has just two parameters, $\\alpha$ and $\\beta$, and we assumed a simple, independent and identically distributed (iid) Gaussian error model to construct the likelihood function. However, it is important to realise that the likelihood function itself is **not** a simple Gaussian: the likelihood function is a combination of the deterministic (\"black box\") environmental model, plus the simple Gaussian error structure. We don't know what calculations are performed inside the black box, so we can't write down an algebraic equation for our likelihood function. Even if we could look at the equations inside the box, we'd probably find a complicated set of ordinary differential equations, and we still wouldn't be able to write down a neat equation for our likelihood. What we *can* do is evaluate the posterior density for any point in the parameter space: we can draw a set of parameters from our prior distribution and then run the model with those parameters. Once we've run the model, we can evaluate the likelihood, then we can multiply the probability of the parameters by the likelihood to get something that is *proportional to* the posterior density.\n",
    "\n",
    "This distinction between what we can and can't do is very important. We're trying to map out the posterior density, and ultimately we want to integrate it to calculate marginal distributions for our model parameters. Unfortuantely, we **cannot** write down the posterior density in a form that we can visualise or integrate analytically, but we **can** evaluate the posterior density at any point within the model's parameter space.\n",
    "\n",
    "Going from being able to sample the posterior density at a discrete number of points to being able to describe it in its entirety will turn out to be pretty challenging. The first step is to introduce some basic **numerical methods**.\n",
    "\n",
    "# 2. Numerical methods\n",
    "\n",
    "This section will begin by taking a detour away from model calibration to look at the more general problem of how we can integrate difficult functions that have no analytical solution. Once we've introduced some of the basic methods, we'll return to Bayiesin model calibration to see how they can be applied.\n",
    "\n",
    "In one dimension, the general problem (as noted above) is that we have *something*, $P(x)$, that is proportional to a posterior density and that we can evaluate at any point $x$, but which we cannot integrate **analytically**. Our aims are to:\n",
    "\n",
    "1. Come up with a method for estimating the shape of the distribution $P(x)$ (because even though we can evaluate it, we don't know what it looks like), and <br><br>\n",
    "\n",
    "2. Find **numerical approximations** to integrals over $P(x)$ that are accurate enough for our purposes.\n",
    "\n",
    "## 2.1. Riemann sum\n",
    "\n",
    "The Riemann sum is perhaps the most obvious way of approximating an integral and it's one that you may have come across before.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAAFtCAYAAAATY4N4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18e66748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def riemannplot(fct,a,b,n):\n",
    "    smoothh = (b-a)/100.0\n",
    "    x = np.arange(a,b+smoothh,smoothh)\n",
    "    plt.plot(x,fct(x))\n",
    "    h = (float(b) - float(a))/float(n)\n",
    "    riemannx = np.arange(a,b,h)\n",
    "    riemanny = fct(riemannx)\n",
    "    plt.bar(riemannx,riemanny,width=h,alpha=0.5,facecolor='orange')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('f(x)')\n",
    "    plt.title('Riemann Left Sum for f(x)')\n",
    "    #plt.xlim(-1,2)\n",
    "    plt.show()\n",
    "\n",
    "def f(x):\n",
    "    return x**3-2*x**2+0.5*x+0.5\n",
    "\n",
    "riemannplot(f,-1,2,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Monte Carlo (MC)\n",
    "\n",
    "Umbrella term for lots of different methods involving random sampling. Number of samples required doesn't balloon in high dimensional spaces = useful. Huge subject - just scratch surface.\n",
    "\n",
    "### 2.2.1. Integration and expected values\n",
    "\n",
    "mcIntegration PDF.\n",
    "\n",
    "### 2.2.2. Importance sampling\n",
    "\n",
    "Evaluate any integral. Choose p(x) wisely!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "def f(x):\n",
    "    \"\"\" This is the function we want to integrate.\n",
    "    \"\"\"\n",
    "    return (np.sin(x)**2 + 0.3)*np.exp(-0.5*x**2)\n",
    "\n",
    "# The function has an analytical solution in this case, so we'll calculate \n",
    "# an exact value to compare out estimates to. \n",
    "true_val = (8*np.exp(2) - 5)*((np.pi/2)**0.5)/(5*np.exp(2))\n",
    "\n",
    "# Range of x values for plotting\n",
    "x = np.arange(-4, 4, 0.1)\n",
    "\n",
    "# We'll try two differing \"sampler densities\": a uniform distribution and a Gaussian\n",
    "norm = stats.norm(loc=0, scale=1)          # mu=0 and sd=1\n",
    "unif = stats.uniform(loc=-10, scale=20)    # min=-10, max=10\n",
    "\n",
    "# Get densities to plot\n",
    "sampler_norm = norm.pdf(x)\n",
    "sampler_unif = unif.pdf(x)\n",
    "f_x = f(x)\n",
    "\n",
    "# Importance sampling\n",
    "# Try a variety of different sample sizes\n",
    "samp_sizes = range(10, 2000, 20)\n",
    "\n",
    "# Lists to store results\n",
    "unif_est = []\n",
    "norm_est = []\n",
    "\n",
    "# Loop over sample sizes\n",
    "for item in samp_sizes:\n",
    "    # Draw the desired number of samples from the sampler densities\n",
    "    uni_samp = unif.rvs(item)\n",
    "    norm_samp = norm.rvs(item)\n",
    "\n",
    "    # Evaluate p_i and f_i for uniform sampler density \n",
    "    p_i_uni = unif.pdf(uni_samp)\n",
    "    f_i_uni = f(uni_samp)\n",
    "    \n",
    "    # Expected value from uniform density\n",
    "    exptd_uni = (f_i_uni/p_i_uni).mean()\n",
    "    unif_est.append(exptd_uni)\n",
    "\n",
    "    # Repeat for Gaussian sampler density\n",
    "    p_i_norm = norm.pdf(norm_samp)\n",
    "    f_i_norm = f(norm_samp)\n",
    "    exptd_norm = (f_i_norm/p_i_norm).mean()\n",
    "    norm_est.append(exptd_norm)\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(17,5))\n",
    "\n",
    "# Target function and sampler densities\n",
    "axes[0].plot(x, f_x, 'k-', lw=2, label='Target distribution')\n",
    "axes[0].plot(x, sampler_norm, 'r-', label='Gaussian sampler density')\n",
    "axes[0].plot(x, sampler_unif, 'b-', label='Uniform sampler density')\n",
    "axes[0].set_xlabel('$x$')\n",
    "axes[0].set_ylabel('Probability density')\n",
    "axes[0].legend(loc='best')\n",
    "\n",
    "# Results based on different sample sizes and sampler densities\n",
    "axes[1].plot(samp_sizes, norm_est, 'r-', lw=1, label='Gaussian sampler density')\n",
    "axes[1].plot(samp_sizes, unif_est, 'b-', lw=1, label='Uniform sampler density')\n",
    "axes[1].axhline(true_val, lw=2, color='k', label='True (analytical) solution')\n",
    "axes[1].set_xlabel('Sample size')\n",
    "axes[1].set_ylabel('Estimated value')\n",
    "axes[1].legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3. Rejection sampling\n",
    "\n",
    "Importance sampling only any good for estimating expected values (i.e. integrals). This is helpful in model calibration, as we can now perform the integrals of things that we couldn't otherwise integrate (like marginal densities). However, it would be more useful to have a mtehod that simply generate a representative sample from the posterior. This is more flexinble, and we can marginalise by calculating marginal histograms based on the sample. Rejection sampling does this.\n",
    "\n",
    "#### Uniform rejection sampling\n",
    "\n",
    "#### Non-unifrom rejection sampling\n",
    "\n",
    "A bit like importance sampling in that it focuses attention towards the most important parts of the distribution. Repeat example above. \n",
    "\n",
    "### 2.2.4. Performance in high dimensional spaces\n",
    "\n",
    "Neither methods work well in high D spaces (see MacKay). List some of other difficulties too.\n",
    "\n",
    "## 2.3. Markov chain Monte Carlo (MCMC)\n",
    "\n",
    "### 2.3.1. Metropolis algorithm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
